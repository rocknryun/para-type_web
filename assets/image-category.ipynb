{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 필요한 라이브러리 설치하기\n",
        "!git clone https://github.com/ndb796/bing_image_downloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "from bing_image_downloader.bing_image_downloader import downloader\n",
        "\n",
        "\n",
        "directory_list = [\n",
        "    './custom_dataset/train/',\n",
        "    './custom_dataset/test/',\n",
        "]\n",
        "\n",
        "# 초기 디렉토리 만들기\n",
        "for directory in directory_list:\n",
        "    if not os.path.isdir(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "# 수집한 이미지를 학습 데이터와 평가 데이터로 구분하는 함수\n",
        "def dataset_split(query, train_cnt):\n",
        "    # 학습 및 평가 데이터셋 디렉토리 만들기\n",
        "    for directory in directory_list:\n",
        "        if not os.path.isdir(directory + '/' + query):\n",
        "            os.makedirs(directory + '/' + query)\n",
        "    # 학습 및 평가 데이터셋 준비하기\n",
        "    cnt = 0\n",
        "    for file_name in os.listdir(query):\n",
        "        if cnt < train_cnt:\n",
        "            print(f'[Train Dataset] {file_name}')\n",
        "            shutil.move(query + '/' + file_name, './custom_dataset/train/' + query + '/' + file_name)\n",
        "        else:\n",
        "            print(f'[Test Dataset] {file_name}')\n",
        "            shutil.move(query + '/' + file_name, './custom_dataset/test/' + query + '/' + file_name)\n",
        "        cnt += 1\n",
        "    shutil.rmtree(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "query = 'romantic'\n",
        "downloader.download(query, limit=40,  output_dir='./', adult_filter_off=True, force_replace=False, timeout=60)\n",
        "dataset_split(query, 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "query = 'gloomy'\n",
        "downloader.download(query, limit=40,  output_dir='./', adult_filter_off=True, force_replace=False, timeout=60)\n",
        "dataset_split(query, 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "query = 'plain'\n",
        "downloader.download(query, limit=40,  output_dir='./', adult_filter_off=True, force_replace=False, timeout=60)\n",
        "dataset_split(query, 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "query = 'colorful'\n",
        "downloader.download(query, limit=40,  output_dir='./', adult_filter_off=True, force_replace=False, timeout=60)\n",
        "dataset_split(query, 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "query = 'lonely'\n",
        "downloader.download(query, limit=40,  output_dir='./', adult_filter_off=True, force_replace=False, timeout=60)\n",
        "dataset_split(query, 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "query = 'antique'\n",
        "downloader.download(query, limit=40,  output_dir='./', adult_filter_off=True, force_replace=False, timeout=60)\n",
        "dataset_split(query, 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "query = 'demansional'\n",
        "downloader.download(query, limit=40,  output_dir='./', adult_filter_off=True, force_replace=False, timeout=60)\n",
        "dataset_split(query, 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "query = 'extravagant'\n",
        "downloader.download(query, limit=40,  output_dir='./', adult_filter_off=True, force_replace=False, timeout=60)\n",
        "dataset_split(query, 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "query = 'high-end'\n",
        "downloader.download(query, limit=40,  output_dir='./', adult_filter_off=True, force_replace=False, timeout=60)\n",
        "dataset_split(query, 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # device 객체"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 데이터셋을 불러올 때 사용할 변형(transformation) 객체 정의\n",
        "transforms_train = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(), # 데이터 증진(augmentation)\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # 정규화(normalization)\n",
        "])\n",
        "\n",
        "transforms_test = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "data_dir = './custom_dataset'\n",
        "train_datasets = datasets.ImageFolder(os.path.join(data_dir, 'train'), transforms_train)\n",
        "test_datasets = datasets.ImageFolder(os.path.join(data_dir, 'test'), transforms_test)\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(train_datasets, batch_size=4, shuffle=True, num_workers=4)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_datasets, batch_size=4, shuffle=True, num_workers=4)\n",
        "\n",
        "print('학습 데이터셋 크기:', len(train_datasets))\n",
        "print('테스트 데이터셋 크기:', len(test_datasets))\n",
        "\n",
        "class_names = train_datasets.classes\n",
        "print('클래스:', class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def imshow(input, title):\n",
        "    # torch.Tensor를 numpy 객체로 변환\n",
        "    input = input.numpy().transpose((1, 2, 0))\n",
        "    # 이미지 정규화 해제하기\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    input = std * input + mean\n",
        "    input = np.clip(input, 0, 1)\n",
        "    # 이미지 출력\n",
        "    plt.imshow(input)\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# 학습 데이터를 배치 단위로 불러오기\n",
        "iterator = iter(train_dataloader)\n",
        "\n",
        "# 현재 배치를 이용해 격자 형태의 이미지를 만들어 시각화\n",
        "inputs, classes = next(iterator)\n",
        "out = torchvision.utils.make_grid(inputs)\n",
        "imshow(out, title=[class_names[x] for x in classes])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = models.resnet34(pretrained=True)\n",
        "num_features = model.fc.in_features\n",
        "# 전이 학습(transfer learning): 모델의 출력 뉴런 수를 3개로 교체하여 마지막 레이어 다시 학습\n",
        "model.fc = nn.Linear(num_features, 9)\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_epochs = 50\n",
        "model.train()\n",
        "start_time = time.time()\n",
        "\n",
        "# 전체 반복(epoch) 수 만큼 반복하며\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.\n",
        "    running_corrects = 0\n",
        "\n",
        "    # 배치 단위로 학습 데이터 불러오기\n",
        "    for inputs, labels in train_dataloader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # 모델에 입력(forward)하고 결과 계산\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # 역전파를 통해 기울기(gradient) 계산 및 학습 진행\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "    epoch_loss = running_loss / len(train_datasets)\n",
        "    epoch_acc = running_corrects / len(train_datasets) * 100.\n",
        "\n",
        "    # 학습 과정 중에 결과 출력\n",
        "    print('#{} Loss: {:.4f} Acc: {:.4f}% Time: {:.4f}s'.format(epoch, epoch_loss, epoch_acc, time.time() - start_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.eval()\n",
        "start_time = time.time()\n",
        "\n",
        "with torch.no_grad():\n",
        "    running_loss = 0.\n",
        "    running_corrects = 0\n",
        "\n",
        "    for inputs, labels in test_dataloader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        # 한 배치의 첫 번째 이미지에 대하여 결과 시각화\n",
        "        print(f'[예측 결과: {class_names[preds[0]]}] (실제 정답: {class_names[labels.data[0]]})')\n",
        "        imshow(inputs.cpu().data[0], title='predict result: ' + class_names[preds[0]])\n",
        "\n",
        "    epoch_loss = running_loss / len(test_datasets)\n",
        "    epoch_acc = running_corrects / len(test_datasets) * 100.\n",
        "    print('[Test Phase] Loss: {:.4f} Acc: {:.4f}% Time: {:.4f}s'.format(epoch_loss, epoch_acc, time.time() - start_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 테스트용 이미지 다운로드하기\n",
        "!wget https://images.unsplash.com/photo-1518895949257-7621c3c786d7?ixlib=rb-1.2.1.jpg -O test_image.jpg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "\n",
        "image = Image.open('test_image.jpg')\n",
        "image = transforms_test(image).unsqueeze(0).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(image)\n",
        "    _, preds = torch.max(outputs, 1)\n",
        "    imshow(image.cpu().data[0], title='predict result: ' + class_names[preds[0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 테스트용 이미지 다운로드하기\n",
        "!wget https://images.unsplash.com/photo-1585377776757-396916bea17f?ixlib=rb-1.2.1 -O test_image2.jpg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "\n",
        "image = Image.open('test_image2.jpg')\n",
        "image = transforms_test(image).unsqueeze(0).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(image)\n",
        "    _, preds = torch.max(outputs, 1)\n",
        "    imshow(image.cpu().data[0], title='predict result: ' + class_names[preds[0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 필요한 라이브러리 설치하기\n",
        "!pip install flask-ngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import io\n",
        "from flask_ngrok import run_with_ngrok\n",
        "from flask import Flask, jsonify, request\n",
        "\n",
        "\n",
        "# 이미지를 읽어 결과를 반환하는 함수\n",
        "def get_prediction(image_bytes):\n",
        "    image = Image.open(io.BytesIO(image_bytes))\n",
        "    image = transforms_test(image).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(image)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        imshow(image.cpu().data[0], title='예측 결과: ' + class_names[preds[0]])\n",
        "\n",
        "    return class_names[preds[0]]\n",
        "\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "\n",
        "@app.route('/', methods=['POST'])\n",
        "def predict():\n",
        "    if request.method == 'POST':\n",
        "        # 이미지 바이트 데이터 받아오기\n",
        "        file = request.files['file']\n",
        "        image_bytes = file.read()\n",
        "\n",
        "        # 분류 결과 확인 및 클라이언트에게 결과 반환\n",
        "        class_name = get_prediction(image_bytes=image_bytes)\n",
        "        print(\"결과:\", {'class_name': class_name})\n",
        "        return jsonify({'class_name': class_name})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "run_with_ngrok(app)\n",
        "app.run()"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "c763eee1c439d09faa57a7ee1149df887d6e548012aca7ce060fb4e4b99d18ff"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
